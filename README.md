# AI Interviewer Platform

Enterprise-grade AI-powered technical interview automation platform.

**Version:** 2.1.0  
**Status:** Production Ready  
**License:** Proprietary

---

## Table of Contents

1. [Overview](#overview)
2. [Features](#features)
3. [Architecture](#architecture)
4. [Configuration](#configuration)
5. [User Guide](#user-guide)
6. [API Documentation](#api-documentation)
7. [Development](#development)
8. [Testing](#testing)
9. [Deployment](#deployment)
10. [Troubleshooting](#troubleshooting)

---

## Overview

The AI Interviewer Platform automates technical interviews using artificial intelligence, providing consistent candidate evaluation at scale. The system conducts real-time voice interviews, transcribes responses, analyzes resumes for ATS compatibility, and generates objective hiring recommendations.

### Key Capabilities

- **AI-Powered Interviews**: Automated technical interviews with real-time speech recognition using AssemblyAI
- **Intelligent Question Generation**: Context-aware questions generated by Google Gemini AI based on job descriptions
- **ATS Resume Analysis**: Comprehensive resume scoring across 7 categories with actionable feedback
- **Multi-Role Access Control**: Dedicated portals for System Admins, HR Managers, Employees, and Candidates
- **Real-Time Evaluation**: Instant scoring and verdict generation (Pass/Review/Fail)
- **Candidate Pipeline Management**: Full lifecycle tracking from application to hiring decision
- **Bulk Operations**: CSV import for candidates, bulk delete capabilities

---

## Features

### For HR Managers

| Feature | Description |
|---------|-------------|
| Candidate Management | Add, edit, delete, and track candidates through hiring pipeline |
| Job Templates | Create job listings with descriptions and AI-generated questions |
| Interview Scheduling | Schedule AI interviews with automatic token generation |
| Bulk Import | Import candidates via CSV file upload |
| Results Dashboard | View interview transcripts, scores, and AI verdicts |
| Pagination and Filtering | Navigate large candidate lists efficiently |

### For Candidates

| Feature | Description |
|---------|-------------|
| ATS Resume Checker | Upload resume and get detailed ATS compatibility analysis |
| Interview Portal | Access scheduled interviews via secure token links |
| Voice Interview | Participate in AI-conducted interviews with real-time transcription |
| Results Access | View interview outcomes and feedback |

### For System Administrators

| Feature | Description |
|---------|-------------|
| Company Management | Approve/reject company registration requests |
| User Administration | Manage users across all companies |
| System Monitoring | Health checks and service status |

### For Employees (Hiring Managers)

| Feature | Description |
|---------|-------------|
| Assigned Candidates | Review candidates assigned for evaluation |
| Interview Results | Access transcripts and AI assessments |
| Hiring Decisions | Make informed recommendations based on data |

---

## Architecture

### System Components

```
                           +------------------+
                           |   Load Balancer  |
                           +--------+---------+
                                    |
          +-------------------------+-------------------------+
          |                         |                         |
+---------v---------+    +----------v----------+    +---------v---------+
|     Frontend      |    |       Backend       |    |    AI Service     |
|   (Next.js:3000)  |    |   (FastAPI:8000)    |    |   (Internal:9002) |
+---------+---------+    +----------+----------+    +---------+---------+
          |                         |                         |
          |              +----------+----------+              |
          |              |                     |              |
          |    +---------v-------+   +---------v-------+      |
          |    |   PostgreSQL    |   |      Redis      |      |
          |    |     (5432)      |   |     (6379)      |      |
          |    +-----------------+   +-----------------+      |
          |                                                   |
          +-------------------+-------------------+-----------+
                              |                   |
                    +---------v-------+  +--------v--------+
                    |   WS Proxy      |  |  Celery Worker  |
                    |    (9003)       |  |                 |
                    +-----------------+  +-----------------+
```

### Service Details

| Service | Port | Technology | Purpose |
|---------|------|------------|---------|
| Frontend | 3000 | Next.js 15, React 18, TypeScript, Tailwind CSS | User interface for all roles |
| Backend | 8000 | FastAPI, Python 3.11, SQLAlchemy 2.0 | REST API, business logic, authentication |
| AI Service | 9002 | Next.js, Node.js | AI interview conductor |
| WebSocket Proxy | 9003 | Node.js | Real-time audio streaming to AssemblyAI |
| PostgreSQL | 5432 | PostgreSQL 15 | Primary data store |
| Redis | 6379 | Redis Alpine | Caching, sessions, task broker |
| Celery Worker | N/A | Python, Celery | Background task processing |

### External Integrations

| Service | Purpose |
|---------|---------|
| Google Gemini AI | Question generation, ATS analysis, interview evaluation |
| AssemblyAI | Real-time speech-to-text transcription |

### Project Structure

```
AI_Interviewer/
├── backend/
│   ├── app/
│   │   ├── core/           # Configuration, database, Celery
│   │   ├── middleware/     # Auth, logging, rate limiting
│   │   ├── models/         # SQLAlchemy models
│   │   ├── routes/         # API endpoints
│   │   ├── schemas/        # Pydantic schemas
│   │   ├── services/       # Business logic, AI service
│   │   ├── tasks/          # Celery tasks
│   │   ├── templates/      # Email templates
│   │   └── utils/          # Helper utilities
│   ├── alembic/            # Database migrations
│   │   └── versions/       # Migration files (001-018)
│   ├── tests/              # Test files
│   ├── scripts/            # Utility scripts
│   ├── Dockerfile
│   └── requirements.txt
├── frontend/
│   ├── src/
│   │   ├── app/            # Next.js pages
│   │   ├── components/     # React components
│   │   ├── contexts/       # React contexts
│   │   ├── hooks/          # Custom hooks
│   │   ├── lib/            # Utilities
│   │   ├── middleware/     # Next.js middleware
│   │   ├── services/       # API services
│   │   └── types/          # TypeScript types
│   ├── public/             # Static assets
│   ├── Dockerfile
│   └── package.json
├── AI/
│   └── Aigenthix_AI_Interviewer/
│       ├── src/
│       ├── data/
│       ├── scripts/
│       └── nginx/
├── docker-compose.yml
├── docker-compose.prod.yml
├── Dockerfile.backend
├── Dockerfile.frontend
├── Dockerfile.ai-service
├── Dockerfile.celery
├── PRD.md
├── TRD.md
└── README.md
```

---

## Configuration

### Environment Variables

Create a `.env` file in the project root with the following variables:

```bash
# Database Configuration
DATABASE_URL=postgresql://ai_interviewer_user:ai_interviewer_password@postgres:5432/ai_interviewer_db

# Redis Configuration
REDIS_URL=redis://redis:6379/0

# Security
SECRET_KEY=your-secure-256-bit-secret-key-here
ALGORITHM=HS256

# AI Service Configuration
AI_SERVICE_API_KEY=your-google-gemini-api-key
AI_SERVICE_MODEL=gemini-2.5-flash
GOOGLE_API_KEY=your-google-gemini-api-key
AI_SERVICE_URL=http://ai-service:9002

# AssemblyAI Configuration
ASSEMBLYAI_API_KEY=your-assemblyai-api-key

# CORS Configuration
CORS_ORIGINS=["http://localhost:3000","http://localhost:3001"]

# Frontend Configuration
NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1
NEXT_PUBLIC_WS_PROXY_URL=ws://localhost:9003

# Token Configuration
ACCESS_TOKEN_EXPIRE_MINUTES=15
REFRESH_TOKEN_EXPIRE_DAYS=7

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# Email Configuration (Optional)
SENDGRID_API_KEY=your-sendgrid-api-key
FROM_EMAIL=noreply@yourcompany.com
```

### Database Configuration

The platform uses PostgreSQL 15 with the following default configuration:

| Parameter | Default Value |
|-----------|---------------|
| Host | postgres (container) |
| Port | 5432 |
| Database | ai_interviewer_db |
| User | ai_interviewer_user |
| Password | ai_interviewer_password |

For production, configure:
- Connection pooling (default: 20 connections)
- SSL/TLS encryption
- Regular backups
- Read replicas for scaling

### Access Points

| Interface | URL | Description |
|-----------|-----|-------------|
| Frontend | http://localhost:3000 | Main application interface |
| Backend API | http://localhost:8000 | REST API endpoints |
| API Documentation | http://localhost:8000/docs | Interactive Swagger documentation |
| Health Check | http://localhost:8000/health | Service health status |

### Default Test Credentials

After running the seed script, use these credentials for testing:

| Role | Email | Password |
|------|-------|----------|
| System Admin | admin@system.local | AdminPass123! |
| HR Manager | hr@techcorp.com | HRPass123! |

---

## User Guide

### HR Manager Workflow

#### 1. Creating a Job Template

1. Log in with HR credentials
2. Navigate to "Jobs" section from sidebar
3. Click "Create New Job"
4. Enter job title and description
5. (Optional) Add custom AI prompt for question context
6. Click "Create Job"

#### 2. Generating Interview Questions

1. Navigate to "Jobs" section
2. Find the job template
3. Click "Generate Questions" button
4. Wait for AI to generate questions (runs as background task)
5. View generated questions in job details

#### 3. Adding Candidates

**Individual Candidate:**

1. Navigate to "Candidates" section
2. Click "Add Candidate"
3. Fill in candidate details (name, email, phone)
4. Optionally upload resume
5. Click "Save"

**Bulk Import:**

1. Navigate to "Candidates" section
2. Click "Bulk Import"
3. Upload CSV file with columns: name, email, phone
4. System processes and imports candidates
5. Review import results

#### 4. Scheduling Interviews

1. Navigate to "Schedule Interview" section
2. Select candidate from dropdown
3. Select job template
4. Choose interview round (Round 1, Round 2, etc.)
5. Set scheduled date and time
6. Click "Schedule"
7. Interview link is generated for candidate

### Candidate Workflow

#### 1. ATS Resume Check

1. Log in to Candidate Portal
2. Navigate to "ATS Resume Checker"
3. Upload resume (PDF, DOCX, or TXT)
4. Optionally enter target job description
5. Click "Analyze My Resume"
6. Review detailed analysis:
   - Overall ATS score (0-100)
   - Section scores (each out of 5)
   - Highlights (strengths)
   - Improvements needed
   - Keywords found and missing

#### 2. Taking an Interview

1. Access interview via provided link or portal
2. Grant microphone permission when prompted
3. Wait for AI interviewer to start
4. Listen to questions and respond verbally
5. AI transcribes and evaluates responses in real-time
6. Complete all questions
7. Interview ends with results generated

### System Admin Workflow

#### 1. Approving Company Registrations

1. Log in with System Admin credentials
2. Navigate to "Admin" section
3. View "Pending Company Requests"
4. Review company details
5. Click "Approve" or "Reject"
6. Approved companies can begin operations

---

## API Documentation

### Base URL

All API endpoints are prefixed with `/api/v1/`.

### Authentication

The API uses JWT Bearer token authentication:

```bash
# Login to get token
curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email": "user@example.com", "password": "password"}'

# Use token in subsequent requests
curl -X GET http://localhost:8000/api/v1/candidates \
  -H "Authorization: Bearer <access_token>"
```

### Key Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | /auth/login | User authentication |
| POST | /auth/logout | Token invalidation |
| GET | /auth/me | Current user info |
| GET | /candidates | List candidates (paginated) |
| POST | /candidates | Create candidate |
| POST | /candidates/bulk-import | Bulk import via CSV |
| DELETE | /candidates/bulk-delete | Bulk delete candidates |
| GET | /jobs | List job templates |
| POST | /jobs | Create job template |
| POST | /jobs/{id}/generate-questions | Generate AI questions |
| POST | /interviews | Schedule interview |
| GET | /interviews/{id}/transcript | Get interview transcript |
| GET | /interviews/validate/{token} | Validate interview token |
| POST | /ai/ats-check | Analyze resume for ATS |
| GET | /ai/reports | List AI reports |

### Interactive Documentation

Access the full interactive API documentation at:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

---

## Development

### Local Development

#### Backend Development

```bash
# Enter backend container
docker compose exec backend bash

# Run development server with auto-reload
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Create new migration
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head

# Rollback migration
alembic downgrade -1
```

#### Frontend Development

```bash
# Enter frontend container
docker compose exec frontend sh

# Run development server
npm run dev

# Build for production
npm run build

# Run linting
npm run lint

# Type checking
npm run type-check
```

### Code Style

#### Python (Backend)

- Follow PEP 8 guidelines
- Use type hints
- Document with docstrings
- Run `black` for formatting
- Run `isort` for import sorting

```bash
# Format code
black backend/
isort backend/

# Type checking
mypy backend/
```

#### TypeScript (Frontend)

- Follow Airbnb style guide
- Use TypeScript strict mode
- Document complex functions

```bash
# Lint code
npm run lint

# Type checking
npm run type-check
```

### Adding New Features

1. **Database Changes:**
   ```bash
   # Create migration
   docker compose exec backend alembic revision --autogenerate -m "add_new_feature"
   
   # Apply migration
   docker compose exec backend alembic upgrade head
   ```

2. **Backend API:**
   - Add model in `backend/app/models/`
   - Add schema in `backend/app/schemas/`
   - Add route in `backend/app/routes/`
   - Register route in `backend/app/main.py`

3. **Frontend:**
   - Add page in `frontend/src/app/`
   - Add components in `frontend/src/components/`
   - Update types in `frontend/src/types/`

---

## Testing

### Backend Tests

```bash
# Run all tests
docker compose exec backend pytest

# Run with coverage report
docker compose exec backend pytest --cov=app --cov-report=html

# Run specific test file
docker compose exec backend pytest tests/test_auth.py -v

# Run specific test function
docker compose exec backend pytest tests/test_auth.py::test_login -v
```

### Test Categories

| Test File | Coverage |
|-----------|----------|
| test_auth.py | Authentication, token management |
| test_user.py | User CRUD operations |
| test_interview.py | Interview scheduling, transcripts |
| test_email.py | Email verification |
| test_phase_2_bulk_operations.py | Bulk import/delete |

### Frontend Tests

```bash
cd frontend

# Run tests
npm test

# Run with coverage
npm test -- --coverage

# Run in watch mode
npm test -- --watch
```

### Integration Tests

```bash
# Run integration test script
./integration_test.sh
```

---

## Deployment

### Production Checklist

**Security:**
- [ ] Generate secure SECRET_KEY (256-bit minimum)
- [ ] Configure production database with SSL
- [ ] Enable HTTPS/TLS termination
- [ ] Set secure CORS origins
- [ ] Review rate limiting configuration
- [ ] Remove seed data scripts

**Infrastructure:**
- [ ] Set up monitoring and alerting
- [ ] Configure log aggregation
- [ ] Set up database backups
- [ ] Configure Redis persistence
- [ ] Set resource limits on containers

**Application:**
- [ ] Run database migrations
- [ ] Verify all health checks pass
- [ ] Test all critical user flows
- [ ] Configure email service for notifications

### Docker Production Build

```bash
# Build production images
docker compose -f docker-compose.prod.yml build

# Deploy
docker compose -f docker-compose.prod.yml up -d

# Verify deployment
docker compose -f docker-compose.prod.yml ps
curl https://api.yourdomain.com/health
```

### Health Checks

```bash
# Backend health
curl http://localhost:8000/health

# Database connectivity
curl http://localhost:8000/health/db

# Redis connectivity
docker compose exec redis redis-cli ping
```

---

## Troubleshooting

### Common Issues

#### Services Not Starting

```bash
# Check service status
docker compose ps

# View service logs
docker compose logs backend
docker compose logs frontend
docker compose logs ai-service

# Restart all services
docker compose down
docker compose up -d
```

#### Database Connection Failed

```bash
# Check PostgreSQL status
docker compose ps postgres

# View PostgreSQL logs
docker compose logs postgres

# Reset database (WARNING: deletes all data)
docker compose down -v
docker compose up -d
docker compose exec backend alembic upgrade head
```

#### AI Service Errors

**Rate Limiting (429 Error):**

The Gemini API has rate limits. Wait a few minutes before retrying. The system automatically retries with exponential backoff.

**API Key Issues:**

```bash
# Verify API key is set
docker compose exec backend env | grep AI_SERVICE_API_KEY

# Update API key
# Edit .env file, then:
docker compose up -d --build backend celery_worker
```

#### WebSocket Connection Issues

```bash
# Check WebSocket proxy status
docker compose logs ai-ws-proxy

# Verify AssemblyAI API key
docker compose exec ai-ws-proxy env | grep ASSEMBLYAI_API_KEY
```

#### Frontend Build Errors

```bash
# Clear Next.js cache
docker compose exec frontend rm -rf .next node_modules
docker compose exec frontend npm install
docker compose exec frontend npm run build

# Rebuild frontend container
docker compose up -d --build frontend
```

### Viewing Logs

```bash
# All services
docker compose logs -f

# Specific service
docker compose logs -f backend

# Last 100 lines
docker compose logs --tail=100 backend

# Celery worker logs
docker compose logs -f celery_worker
```

### Performance Issues

1. **Slow API Responses:**
   - Check database query performance
   - Review connection pool settings
   - Enable query logging for debugging

2. **High Memory Usage:**
   - Review container resource limits
   - Check for memory leaks in long-running processes
   - Monitor Redis memory usage

3. **Slow AI Operations:**
   - AI tasks run asynchronously via Celery
   - Check Celery worker logs for task status
   - Monitor external API response times

---

## Support

For issues, feature requests, or contributions:

- GitHub Issues: Report bugs and request features
- Pull Requests: Contributions welcome following the development guidelines

---

## License

This software is proprietary. All rights reserved.

Copyright 2024-2026 Aigenthix. Unauthorized copying, modification, or distribution is prohibited.
