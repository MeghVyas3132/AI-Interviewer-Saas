# AI Interviewer Platform# AI Interviewer Platform



Enterprise-grade AI-powered technical interview automation platform.Enterprise-grade AI-powered technical interview automation platform.



**Version:** 2.1.0  **Version:** 2.0.0  

**Status:** Production Ready  **Status:** Production Ready  

**License:** Proprietary**License:** Proprietary



------



## Table of Contents## Table of Contents



1. [Overview](#overview)1. [Overview](#overview)

2. [Features](#features)2. [Quick Start](#quick-start)

3. [Architecture](#architecture)3. [Architecture](#architecture)

4. [Quick Start](#quick-start)4. [Installation](#installation)

5. [Configuration](#configuration)5. [Configuration](#configuration)

6. [User Guide](#user-guide)6. [API Documentation](#api-documentation)

7. [API Documentation](#api-documentation)7. [Development](#development)

8. [Development](#development)8. [Testing](#testing)

9. [Testing](#testing)9. [Deployment](#deployment)

10. [Deployment](#deployment)10. [Troubleshooting](#troubleshooting)

11. [Troubleshooting](#troubleshooting)11. [Contributing](#contributing)



------



## Overview## Overview



The AI Interviewer Platform automates technical interviews using artificial intelligence, providing consistent candidate evaluation at scale. The system conducts real-time voice interviews, transcribes responses, analyzes resumes for ATS compatibility, and generates objective hiring recommendations.The AI Interviewer Platform automates technical interviews using artificial intelligence, providing consistent candidate evaluation at scale. The system conducts real-time voice interviews, transcribes responses, and generates objective hiring recommendations.



### Key Capabilities### Key Features



- **AI-Powered Interviews**: Automated technical interviews with real-time speech recognition using AssemblyAI- **AI-Powered Interviews**: Automated technical interviews with real-time speech recognition

- **Intelligent Question Generation**: Context-aware questions generated by Google Gemini AI based on job descriptions- **ATS Integration**: Resume parsing and compatibility scoring

- **ATS Resume Analysis**: Comprehensive resume scoring across 7 categories with actionable feedback- **Multi-Role Access**: Admin, HR, Employee, and Candidate portals

- **Multi-Role Access Control**: Dedicated portals for System Admins, HR Managers, Employees, and Candidates- **Real-Time Evaluation**: Instant scoring and verdict generation

- **Real-Time Evaluation**: Instant scoring and verdict generation (Pass/Review/Fail)- **Transcript Analysis**: Complete interview recording with Q&A breakdown

- **Candidate Pipeline Management**: Full lifecycle tracking from application to hiring decision- **Pipeline Management**: Full candidate lifecycle tracking

- **Bulk Operations**: CSV import for candidates, bulk delete capabilities

### Technology Stack

---

| Layer | Technology |

## Features|-------|------------|

| Frontend | Next.js 15, React 18, TypeScript, Tailwind CSS |

### For HR Managers| Backend | FastAPI, Python 3.11, SQLAlchemy 2.0, Pydantic 2.0 |

| AI Service | Node.js, WebSocket, LLM Integration |

| Feature | Description || Database | PostgreSQL 15 |

|---------|-------------|| Cache | Redis |

| Candidate Management | Add, edit, delete, and track candidates through hiring pipeline || Task Queue | Celery |

| Job Templates | Create job listings with descriptions and AI-generated questions || Containerization | Docker, Docker Compose |

| Interview Scheduling | Schedule AI interviews with automatic token generation |

| Bulk Import | Import candidates via CSV file upload |---

| Results Dashboard | View interview transcripts, scores, and AI verdicts |

| Pagination and Filtering | Navigate large candidate lists efficiently |## Quick Start



### For Candidates### Prerequisites



| Feature | Description |- Docker Desktop 24.0+

|---------|-------------|- Docker Compose 2.0+

| ATS Resume Checker | Upload resume and get detailed ATS compatibility analysis |- Git

| Interview Portal | Access scheduled interviews via secure token links |

| Voice Interview | Participate in AI-conducted interviews with real-time transcription |### Launch Application

| Results Access | View interview outcomes and feedback |

```bash

### For System Administrators# Clone the repository

git clone https://github.com/MeghVyas3132/AI_Interviewer_Saas.git

| Feature | Description |cd AI_Interviewer_Saas

|---------|-------------|

| Company Management | Approve/reject company registration requests |# Start all services

| User Administration | Manage users across all companies |docker compose up -d

| System Monitoring | Health checks and service status |

# Wait for services to be healthy (approximately 30 seconds)

### For Employees (Hiring Managers)docker compose ps



| Feature | Description |# Access the application

|---------|-------------|# Frontend: http://localhost:3000

| Assigned Candidates | Review candidates assigned for evaluation |# Backend API: http://localhost:8000

| Interview Results | Access transcripts and AI assessments |# API Documentation: http://localhost:8000/docs

| Hiring Decisions | Make informed recommendations based on data |```



---### Default Credentials



## ArchitectureAfter initial setup, use these credentials for testing:



### System Components| Role | Email | Password |

|------|-------|----------|

```| Admin | admin@system.local | AdminPass123!@ |

                           +------------------+| HR | hr@techcorp.com | HRPass123!@ |

                           |   Load Balancer  |

                           +--------+---------+---

                                    |

          +-------------------------+-------------------------+## Architecture

          |                         |                         |

+---------v---------+    +----------v----------+    +---------v---------+### System Components

|     Frontend      |    |       Backend       |    |    AI Service     |

|   (Next.js:3000)  |    |   (FastAPI:8000)    |    |   (Internal:3000) |```

+---------+---------+    +----------+----------+    +---------+---------+                        +-------------------+

          |                         |                         |                        |   Load Balancer   |

          |              +----------+----------+              |                        +--------+----------+

          |              |                     |              |                                 |

          |    +---------v-------+   +---------v-------+      |         +-----------------------+-----------------------+

          |    |   PostgreSQL    |   |      Redis      |      |         |                       |                       |

          |    |     (5432)      |   |     (6379)      |      |+--------+--------+    +---------+---------+   +---------+---------+

          |    +-----------------+   +-----------------+      ||    Frontend     |    |     Backend       |   |    AI Service     |

          |                                                   ||   (Next.js)     |    |    (FastAPI)      |   |    (Node.js)      |

          +-------------------+-------------------+-----------+|   Port: 3000    |    |    Port: 8000     |   |    Port: 9002     |

                              |                   |+--------+--------+    +---------+---------+   +---------+---------+

                    +---------v-------+  +--------v--------+         |                       |                       |

                    |   WS Proxy      |  |  Celery Worker  |         |              +--------+--------+              |

                    |    (9003)       |  |                 |         |              |                 |              |

                    +-----------------+  +-----------------+         |       +------+------+  +-------+------+       |

```         |       | PostgreSQL  |  |    Redis     |       |

         |       |  Port: 5432 |  |  Port: 6379  |       |

### Service Details         |       +-------------+  +--------------+       |

         |                                               |

| Service | Port | Technology | Purpose |         +------------------+----------------------------+

|---------|------|------------|---------|                            |

| Frontend | 3000 | Next.js 15, React 18, TypeScript, Tailwind CSS | User interface for all roles |                  +---------+---------+

| Backend | 8000 | FastAPI, Python 3.11, SQLAlchemy 2.0 | REST API, business logic, authentication |                  |   AI WS Proxy     |

| AI Service | Internal | Next.js, Node.js | AI interview conductor |                  |    Port: 9003     |

| WebSocket Proxy | 9003 | Node.js | Real-time audio streaming to AssemblyAI |                  +-------------------+

| PostgreSQL | 5432 | PostgreSQL 15 | Primary data store |```

| Redis | 6379 | Redis Alpine | Caching, sessions, task broker |

| Celery Worker | N/A | Python, Celery | Background task processing |### Service Responsibilities



### External Integrations| Service | Responsibility |

|---------|----------------|

| Service | Purpose || Frontend | User interface, SSR, routing |

|---------|---------|| Backend | REST API, business logic, authentication |

| Google Gemini AI | Question generation, ATS analysis, interview evaluation || AI Service | Interview AI, question generation, evaluation |

| AssemblyAI | Real-time speech-to-text transcription || AI WS Proxy | Real-time WebSocket communication |

| PostgreSQL | Primary data persistence |

---| Redis | Session caching, rate limiting |

| Celery | Background task processing |

## Quick Start

### Data Flow

### Prerequisites

1. **User Authentication**: Frontend -> Backend -> PostgreSQL

- Docker Desktop 24.0 or higher2. **Interview Session**: Frontend -> AI WS Proxy -> AI Service

- Docker Compose 2.0 or higher3. **Transcript Storage**: AI Service -> Backend -> PostgreSQL

- Git4. **ATS Analysis**: Backend -> AI Service -> Backend

- Google Gemini API Key (required for AI features)

- AssemblyAI API Key (required for interview transcription)---



### Installation## Installation



```bash### Development Environment

# Clone the repository

git clone https://github.com/Aigenthix/MicroServices_AI_Interviewer.git```bash

cd AI_Interviewer# 1. Clone repository

git clone https://github.com/MeghVyas3132/AI_Interviewer_Saas.git

# Create environment filecd AI_Interviewer_Saas

cp .env.example .env

# 2. Create environment file

# Edit .env and add your API keyscp .env.example .env

# AI_SERVICE_API_KEY=your-gemini-api-key

# GOOGLE_API_KEY=your-gemini-api-key# 3. Configure environment variables (see Configuration section)

# ASSEMBLYAI_API_KEY=your-assemblyai-api-key

# 4. Build and start services

# Start all servicesdocker compose up -d --build

docker compose up -d

# 5. Run database migrations

# Wait for services to be healthy (approximately 60 seconds)docker compose exec backend alembic upgrade head

docker compose ps

# 6. Seed initial data (development only)

# Run database migrationsdocker compose exec backend python reset_and_seed.py

docker compose exec backend alembic upgrade head

# 7. Verify services

# (Optional) Seed development datadocker compose ps

docker compose exec backend python reset_and_seed.py```

```

### Manual Installation (Without Docker)

### Access Points

#### Backend Setup

| Interface | URL | Description |

|-----------|-----|-------------|```bash

| Frontend | http://localhost:3000 | Main application interface |cd backend

| Backend API | http://localhost:8000 | REST API endpoints |

| API Documentation | http://localhost:8000/docs | Interactive Swagger documentation |# Create virtual environment

| Health Check | http://localhost:8000/health | Service health status |python -m venv venv

source venv/bin/activate  # Linux/macOS

### Default Test Credentials# or: venv\Scripts\activate  # Windows



After running the seed script, use these credentials for testing:# Install dependencies

pip install -r requirements.txt

| Role | Email | Password |

|------|-------|----------|# Set environment variables

| System Admin | admin@system.local | AdminPass123! |export DATABASE_URL="postgresql+asyncpg://user:pass@localhost:5432/ai_interviewer"

| HR Manager | hr@techcorp.com | HRPass123! |export SECRET_KEY="your-256-bit-secret-key"

export REDIS_URL="redis://localhost:6379/0"

---

# Run migrations

## Configurationalembic upgrade head



### Environment Variables# Start server

uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

Create a `.env` file in the project root with the following variables:```



```bash#### Frontend Setup

# Database Configuration

DATABASE_URL=postgresql://ai_interviewer_user:ai_interviewer_password@postgres:5432/ai_interviewer_db```bash

cd frontend

# Redis Configuration

REDIS_URL=redis://redis:6379/0# Install dependencies

npm install

# Security

SECRET_KEY=your-secure-256-bit-secret-key-here# Set environment variables

ALGORITHM=HS256export NEXT_PUBLIC_API_URL="http://localhost:8000/api/v1"



# AI Service Configuration# Start development server

AI_SERVICE_API_KEY=your-google-gemini-api-keynpm run dev

AI_SERVICE_MODEL=gemini-2.5-flash```

GOOGLE_API_KEY=your-google-gemini-api-key

---

# AssemblyAI Configuration

ASSEMBLYAI_API_KEY=your-assemblyai-api-key## Configuration



# CORS Configuration### Environment Variables

CORS_ORIGINS=["http://localhost:3000","http://localhost:3001"]

Create a `.env` file in the project root:

# Frontend Configuration

NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1```bash

NEXT_PUBLIC_WS_PROXY_URL=ws://localhost:9003# Required - Security

```SECRET_KEY=your-super-secret-256-bit-key-here



### Database Configuration# Required - Database

DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/ai_interviewer

The platform uses PostgreSQL 15 with the following default configuration:POSTGRES_USER=postgres

POSTGRES_PASSWORD=postgres

| Parameter | Default Value |POSTGRES_DB=ai_interviewer

|-----------|---------------|

| Host | postgres (container) |# Required - Redis

| Port | 5432 |REDIS_URL=redis://redis:6379/0

| Database | ai_interviewer_db |

| User | ai_interviewer_user |# Required - Service URLs

| Password | ai_interviewer_password |AI_SERVICE_URL=http://ai-service:9002

BACKEND_URL=http://backend:8000

For production, configure:

- Connection pooling (default: 20 connections)# Optional - Email (SendGrid)

- SSL/TLS encryptionSENDGRID_API_KEY=

- Regular backupsFROM_EMAIL=noreply@yourcompany.com

- Read replicas for scaling

# Optional - Email (SMTP)

---SMTP_HOST=

SMTP_PORT=587

## User GuideSMTP_USER=

SMTP_PASSWORD=

### HR Manager Workflow

# Optional - AI Providers

#### 1. Creating a Job TemplateGROQ_API_KEY=



```# Optional - Security Settings

1. Log in with HR credentialsACCESS_TOKEN_EXPIRE_MINUTES=15

2. Navigate to "Jobs" section from sidebarREFRESH_TOKEN_EXPIRE_DAYS=7

3. Click "Create New Job"PASSWORD_MIN_LENGTH=8

4. Enter job title and description

5. (Optional) Add custom AI prompt for question context# Optional - Rate Limiting

6. Click "Create Job"RATE_LIMIT_REQUESTS=100

```RATE_LIMIT_WINDOW=60

```

#### 2. Generating Interview Questions

### Security Configuration

```

1. Navigate to "Jobs" sectionGenerate a secure secret key:

2. Find the job template

3. Click "Generate Questions" button```bash

4. Wait for AI to generate questions (runs as background task)python -c "import secrets; print(secrets.token_urlsafe(32))"

5. View generated questions in job details```

```

---

#### 3. Adding Candidates

## API Documentation

**Individual Candidate:**

```### Authentication

1. Navigate to "Candidates" section

2. Click "Add Candidate"All API endpoints require authentication except:

3. Fill in candidate details (name, email, phone)- `POST /api/v1/auth/login` - User login

4. Optionally upload resume- `GET /api/v1/interviews/validate/{token}` - Interview token validation

5. Click "Save"

```#### Login



**Bulk Import:**```bash

```curl -X POST http://localhost:8000/api/v1/auth/login \

1. Navigate to "Candidates" section  -H "Content-Type: application/json" \

2. Click "Bulk Import"  -d '{"email": "user@example.com", "password": "password"}'

3. Upload CSV file with columns: name, email, phone```

4. System processes and imports candidates

5. Review import resultsResponse:

``````json

{

#### 4. Scheduling Interviews  "access_token": "eyJ...",

  "token_type": "bearer",

```  "user": {

1. Navigate to "Schedule Interview" section    "id": "uuid",

2. Select candidate from dropdown    "email": "user@example.com",

3. Select job template    "role": "HR"

4. Choose interview round (Round 1, Round 2, etc.)  }

5. Set scheduled date and time}

6. Click "Schedule"```

7. Interview link is generated for candidate

```### Core Endpoints



### Candidate Workflow#### Candidates



#### 1. ATS Resume Check| Method | Endpoint | Description |

|--------|----------|-------------|

```| GET | /api/v1/candidates | List all candidates |

1. Log in to Candidate Portal| POST | /api/v1/candidates | Create candidate |

2. Navigate to "ATS Resume Checker"| GET | /api/v1/candidates/{id} | Get candidate details |

3. Upload resume (PDF, DOCX, or TXT)| PATCH | /api/v1/candidates/{id} | Update candidate |

4. Optionally enter target job description| DELETE | /api/v1/candidates/{id} | Delete candidate |

5. Click "Analyze My Resume"| POST | /api/v1/candidates/bulk-import | Bulk import from CSV |

6. Review detailed analysis:

   - Overall ATS score (0-100)#### Interviews

   - Section scores (each out of 5)

   - Highlights (strengths)| Method | Endpoint | Description |

   - Improvements needed|--------|----------|-------------|

   - Keywords found and missing| GET | /api/v1/interviews | List interviews |

```| POST | /api/v1/interviews | Schedule interview |

| GET | /api/v1/interviews/{id} | Get interview details |

#### 2. Taking an Interview| PATCH | /api/v1/interviews/{id} | Update interview |

| GET | /api/v1/interviews/validate/{token} | Validate token |

```

1. Access interview via provided link or portal#### AI Services

2. Grant microphone permission when prompted

3. Wait for AI interviewer to start| Method | Endpoint | Description |

4. Listen to questions and respond verbally|--------|----------|-------------|

5. AI transcribes and evaluates responses in real-time| POST | /api/v1/ai/ats/check | ATS resume analysis |

6. Complete all questions| POST | /api/v1/ai/questions/generate | Generate questions |

7. Interview ends with results generated| GET | /api/v1/ai/reports | List AI reports |

```

### Interactive Documentation

### System Admin Workflow

Access Swagger UI at: `http://localhost:8000/docs`

#### 1. Approving Company Registrations

Access ReDoc at: `http://localhost:8000/redoc`

```

1. Log in with System Admin credentials---

2. Navigate to "Admin" section

3. View "Pending Company Requests"## Development

4. Review company details

5. Click "Approve" or "Reject"### Project Structure

6. Approved companies can begin operations

``````

ai-interviewer/

---├── backend/

│   ├── app/

## API Documentation│   │   ├── core/           # Configuration, database

│   │   ├── middleware/     # Auth, logging, rate limiting

### Base URL│   │   ├── models/         # SQLAlchemy models

│   │   ├── routes/         # API endpoints

All API endpoints are prefixed with `/api/v1/`.│   │   ├── schemas/        # Pydantic schemas

│   │   ├── services/       # Business logic

### Authentication│   │   ├── tasks/          # Celery tasks

│   │   └── utils/          # Helpers

The API uses JWT Bearer token authentication:│   ├── alembic/            # Database migrations

│   └── tests/              # Test suite

```bash├── frontend/

# Login to get token│   ├── src/

curl -X POST http://localhost:8000/api/v1/auth/login \│   │   ├── app/            # Next.js pages

  -H "Content-Type: application/json" \│   │   ├── components/     # React components

  -d '{"email": "user@example.com", "password": "password"}'│   │   ├── contexts/       # React contexts

│   │   ├── hooks/          # Custom hooks

# Use token in subsequent requests│   │   ├── lib/            # Utilities

curl -X GET http://localhost:8000/api/v1/candidates \│   │   └── types/          # TypeScript types

  -H "Authorization: Bearer <access_token>"│   └── public/             # Static assets

```├── AI/                     # AI service

├── docker-compose.yml

### Key Endpoints├── PRD.md                  # Product Requirements

├── TRD.md                  # Technical Requirements

| Method | Endpoint | Description |└── README.md

|--------|----------|-------------|```

| POST | /auth/login | User authentication |

| POST | /auth/logout | Token invalidation |### Code Style

| GET | /auth/me | Current user info |

| GET | /candidates | List candidates (paginated) |#### Python (Backend)

| POST | /candidates | Create candidate |

| POST | /candidates/bulk-import | Bulk import via CSV |- Follow PEP 8 guidelines

| GET | /jobs | List job templates |- Use type hints

| POST | /jobs | Create job template |- Document with docstrings

| POST | /jobs/{id}/generate-questions | Generate AI questions |- Run `black` for formatting

| POST | /interviews | Schedule interview |- Run `isort` for imports

| GET | /interviews/{id}/transcript | Get interview transcript |

| POST | /ai/ats-check | Analyze resume for ATS |```bash

# Format code

### Interactive Documentationblack backend/

isort backend/

Access the full interactive API documentation at:

- Swagger UI: http://localhost:8000/docs# Type checking

- ReDoc: http://localhost:8000/redocmypy backend/

```

---

#### TypeScript (Frontend)

## Development

- Follow Airbnb style guide

### Project Structure- Use TypeScript strict mode

- Document complex functions

```

AI_Interviewer/```bash

├── backend/# Lint code

│   ├── app/npm run lint

│   │   ├── core/           # Configuration, database, Celery

│   │   ├── middleware/     # Auth, logging, rate limiting# Type checking

│   │   ├── models/         # SQLAlchemy modelsnpm run type-check

│   │   ├── routes/         # API endpoints```

│   │   ├── schemas/        # Pydantic schemas

│   │   ├── services/       # Business logic, AI service### Adding New Features

│   │   └── tasks/          # Celery tasks

│   ├── alembic/            # Database migrations1. Create database migration (if needed):

│   ├── tests/              # Test files```bash

│   ├── Dockerfiledocker compose exec backend alembic revision --autogenerate -m "description"

│   └── requirements.txtdocker compose exec backend alembic upgrade head

├── frontend/```

│   ├── src/

│   │   ├── app/            # Next.js pages2. Add model in `backend/app/models/`

│   │   ├── components/     # React components3. Add schema in `backend/app/schemas/`

│   │   ├── contexts/       # React contexts4. Add route in `backend/app/routes/`

│   │   ├── hooks/          # Custom hooks5. Add frontend components

│   │   ├── lib/            # Utilities6. Write tests

│   │   └── types/          # TypeScript types

│   ├── Dockerfile---

│   └── package.json

├── AI/## Testing

│   └── Aigenthix_AI_Interviewer/  # AI interview service

├── docker-compose.yml### Backend Tests

├── PRD.md                  # Product Requirements

├── TRD.md                  # Technical Requirements```bash

└── README.md# Run all tests

```docker compose exec backend pytest



### Local Development# Run with coverage

docker compose exec backend pytest --cov=app --cov-report=html

#### Backend Development

# Run specific test file

```bashdocker compose exec backend pytest tests/test_auth.py -v

# Enter backend container```

docker compose exec backend bash

### Frontend Tests

# Run development server with auto-reload

uvicorn app.main:app --reload --host 0.0.0.0 --port 8000```bash

cd frontend

# Create new migration

alembic revision --autogenerate -m "description"# Run tests

npm test

# Apply migrations

alembic upgrade head# Run with coverage

npm test -- --coverage

# Rollback migration```

alembic downgrade -1

```### Integration Tests



#### Frontend Development```bash

# Run integration test script

```bash./integration_test.sh

# Enter frontend container```

docker compose exec frontend sh

---

# Run development server

npm run dev## Deployment



# Build for production### Production Checklist

npm run build

- [ ] Set secure `SECRET_KEY` (256-bit minimum)

# Run linting- [ ] Configure production database

npm run lint- [ ] Enable HTTPS/TLS

- [ ] Set up monitoring and alerting

# Type checking- [ ] Configure backup strategy

npm run type-check- [ ] Review rate limiting settings

```- [ ] Remove seed data scripts

- [ ] Disable debug logging

### Adding New Features

### Docker Production Build

1. **Database Changes:**

   ```bash```bash

   # Create migration# Build production images

   docker compose exec backend alembic revision --autogenerate -m "add_new_feature"docker compose -f docker-compose.prod.yml build

   

   # Apply migration# Deploy

   docker compose exec backend alembic upgrade headdocker compose -f docker-compose.prod.yml up -d

   ``````



2. **Backend API:**### Health Checks

   - Add model in `backend/app/models/`

   - Add schema in `backend/app/schemas/````bash

   - Add route in `backend/app/routes/`# Backend health

   - Register route in `backend/app/main.py`curl http://localhost:8000/health



3. **Frontend:**# Database connectivity

   - Add page in `frontend/src/app/`curl http://localhost:8000/health/db

   - Add components in `frontend/src/components/````

   - Update types in `frontend/src/types/`

---

---

## Troubleshooting

## Testing

### Common Issues

### Backend Tests

#### Database Connection Failed

```bash

# Run all tests```bash

docker compose exec backend pytest# Check PostgreSQL is running

docker compose ps postgres

# Run with coverage report

docker compose exec backend pytest --cov=app --cov-report=html# View logs

docker compose logs postgres

# Run specific test file

docker compose exec backend pytest tests/test_auth.py -v# Reset database

docker compose down -v

# Run specific test functiondocker compose up -d

docker compose exec backend pytest tests/test_auth.py::test_login -vdocker compose exec backend alembic upgrade head

``````



### Test Categories#### Frontend Build Errors



| Test File | Coverage |```bash

|-----------|----------|# Clear Next.js cache

| test_auth.py | Authentication, token management |cd frontend

| test_user.py | User CRUD operations |rm -rf .next node_modules

| test_interview.py | Interview scheduling, transcripts |npm install

| test_email.py | Email verification |npm run build

| test_phase_2_bulk_operations.py | Bulk import/delete |```



### Frontend Tests#### Redis Connection Issues



```bash```bash

cd frontend# Check Redis status

docker compose exec redis redis-cli ping

# Run tests# Expected: PONG

npm test

# View Redis logs

# Run with coveragedocker compose logs redis

npm test -- --coverage```



# Run in watch mode#### AI Service Not Responding

npm test -- --watch

``````bash

# Check AI service logs

---docker compose logs ai-service



## Deployment# Verify WebSocket proxy

docker compose logs ai-ws-proxy

### Production Checklist```



**Security:**### Logs

- [ ] Generate secure SECRET_KEY (256-bit minimum)

- [ ] Configure production database with SSL```bash

- [ ] Enable HTTPS/TLS termination# View all logs

- [ ] Set secure CORS originsdocker compose logs -f

- [ ] Review rate limiting configuration

- [ ] Remove seed data scripts# View specific service

docker compose logs -f backend

**Infrastructure:**

- [ ] Set up monitoring and alerting# Last 100 lines

- [ ] Configure log aggregationdocker compose logs --tail=100 backend

- [ ] Set up database backups```

- [ ] Configure Redis persistence

- [ ] Set resource limits on containers### Performance Issues



**Application:**1. Check database query performance

- [ ] Run database migrations2. Monitor Redis memory usage

- [ ] Verify all health checks pass3. Review API response times

- [ ] Test all critical user flows4. Check container resource limits

- [ ] Configure email service for notifications

---

### Docker Production Build

## Contributing

```bash

# Build production images### Development Workflow

docker compose -f docker-compose.prod.yml build

1. Fork the repository

# Deploy2. Create feature branch: `git checkout -b feature/new-feature`

docker compose -f docker-compose.prod.yml up -d3. Make changes with tests

4. Run linting and tests

# Verify deployment5. Commit with conventional commits

docker compose -f docker-compose.prod.yml ps6. Push and create pull request

curl https://api.yourdomain.com/health

```### Commit Convention



### Health Checks```

type(scope): description

```bash

# Backend healthTypes: feat, fix, docs, style, refactor, test, chore

curl http://localhost:8000/health```



# Database connectivityExamples:

curl http://localhost:8000/health/db```

feat(auth): add password reset functionality

# Redis connectivityfix(interview): resolve WebSocket disconnection issue

docker compose exec redis redis-cli pingdocs(readme): update installation instructions

``````



---### Pull Request Requirements



## Troubleshooting- [ ] All tests passing

- [ ] Code formatted and linted

### Common Issues- [ ] Documentation updated

- [ ] No security vulnerabilities

#### Services Not Starting- [ ] Review checklist completed



```bash---

# Check service status

docker compose ps## Support



# View service logsFor issues and feature requests, please use the GitHub issue tracker.

docker compose logs backend

docker compose logs frontend---

docker compose logs ai-service

## License

# Restart all services

docker compose downThis software is proprietary. All rights reserved.

docker compose up -d

```Copyright 2024 Aigenthix. Unauthorized copying, modification, or distribution is prohibited.


#### Database Connection Failed

```bash
# Check PostgreSQL status
docker compose ps postgres

# View PostgreSQL logs
docker compose logs postgres

# Reset database (WARNING: deletes all data)
docker compose down -v
docker compose up -d
docker compose exec backend alembic upgrade head
```

#### AI Service Errors

**Rate Limiting (429 Error):**
```
The Gemini API has rate limits. Wait a few minutes before retrying.
The system automatically retries with exponential backoff.
```

**API Key Issues:**
```bash
# Verify API key is set
docker compose exec backend env | grep AI_SERVICE_API_KEY

# Update API key
# Edit .env file, then:
docker compose up -d --build backend celery_worker
```

#### WebSocket Connection Issues

```bash
# Check WebSocket proxy status
docker compose logs ai-ws-proxy

# Verify AssemblyAI API key
docker compose exec ai-ws-proxy env | grep ASSEMBLYAI_API_KEY
```

#### Frontend Build Errors

```bash
# Clear Next.js cache
docker compose exec frontend rm -rf .next node_modules
docker compose exec frontend npm install
docker compose exec frontend npm run build

# Rebuild frontend container
docker compose up -d --build frontend
```

### Viewing Logs

```bash
# All services
docker compose logs -f

# Specific service
docker compose logs -f backend

# Last 100 lines
docker compose logs --tail=100 backend

# Celery worker logs
docker compose logs -f celery_worker
```

### Performance Issues

1. **Slow API Responses:**
   - Check database query performance
   - Review connection pool settings
   - Enable query logging for debugging

2. **High Memory Usage:**
   - Review container resource limits
   - Check for memory leaks in long-running processes
   - Monitor Redis memory usage

3. **Slow AI Operations:**
   - AI tasks run asynchronously via Celery
   - Check Celery worker logs for task status
   - Monitor external API response times

---

## Support

For issues, feature requests, or contributions:

- GitHub Issues: Report bugs and request features
- Pull Requests: Contributions welcome following the development guidelines

---

## License

This software is proprietary. All rights reserved.

Copyright 2024-2026 Aigenthix. Unauthorized copying, modification, or distribution is prohibited.
